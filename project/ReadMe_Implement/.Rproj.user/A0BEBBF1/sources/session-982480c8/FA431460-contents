

library(readme)
data(clinton, package="readme")

class(clinton)

write.csv(clinton, "wocao.csv", row.names = TRUE)

my_data <- read.csv("wocao.csv")



library(tokenizers)
# data.table::fread(file.path(targetDir, "glove.6B.200d.txt"), quote = "")
## Generate a word vector summary for each document
wordVec_summaries = undergrad(documentText = cleanme(clinton$TEXT), wordVecs = NULL)

# Estimate category proportions
set.seed(2138) # Set a seed if you choose
readme.estimates <- readme(dfm = wordVec_summaries , labeledIndicator = clinton$TRAININGSET, categoryVec = clinton$TRUTH)


# Output proportions estimate
readme.estimates$point_readme
# Compare to the truth
table(clinton$TRUTH[clinton$TRAININGSET == 0])/sum(table((clinton$TRUTH[clinton$TRAININGSET == 0])))
